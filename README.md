# AutoML-Comparision
Compare the accuracy/efficiency/operability of different AutoML framework


1.什么是AutoML？

目前一个优秀的机器学习和深度学习模型，离不开这几个方面：
​	一、优秀的数据预处理；
​	二、合适的模型结构和功能；
​	三、优秀的训练策略和超参数；
​	四、合适的后处理操作；
​	五、严格的结果分析。
​	这几方面都对最终的结果有着举足轻重的影响，这也是目前的数据工程师和学者们的主要工作。但由于这每一方面都十分繁琐，尤其是在构建模型和训练模型上。而大部分情况下，这些工作有无须过深专业知识就能使用起来。所以AutoML主要的作用就是来帮助实现高效的模型构建和超参数调整。例如深度学习网络的架构搜索、超参数的重要性分析等等。当然AutoML并不简单的进行暴力或者随机的搜索，其仍然需要机器学习方面的知识，例如贝叶斯优化、强化学习、元学习以及迁移学习等等。目前也有些不错的AutoML工具包，例如Alex Honchar的Hyperopt、微软的NNI、Autokeras等。

2.自动化超参数搜索方法有哪些？

目前自动化搜索主要包含网格搜索，随机搜索，基于模型的超参优化
​	网格搜索：
​	 通常当超参数量较少的时候，可以使用网格搜索法。即列出每个超参数的大致候选集合。利用这些集合	 进行逐项组合优化。在条件允许的情况下，重复进行网格搜索会当优秀，当然每次重复需要根据上一步得到的最优参数组合，进行进一步的细粒度的调整。网格搜索最大的问题就在于计算时间会随着超参数的数量指数级的增长。
​	随机搜索：
​	 随机搜索，是一种用来替代网格搜索的搜索方式。随机搜索有别于网格搜索的一点在于，我们不需要设定一个离散的超参数集合，而是对每个超参数定义一个分布函数来生成随机超参数。随机搜索相比于网格搜索在一些不敏感超参上拥有明显优势。例如网格搜索对于批样本数量（batch size），在[16,32,64]这些范围内进行逐项调试，这样的调试显然收益更低下。当然随机搜索也可以进行细粒度范围内的重复的搜索优化。

​	基于模型的超参优化：
​	 有别于上述两种的搜索策略，基于模型的超参调优问题转化为了优化问题。直觉上会考虑是否进行一个可导建模，然后利用梯度下降进行优化。但不幸的是我们的超参数通常情况下是离散的，而且其计算代价依旧很高。
​	 基于模型的搜索算法，最常见的就是贝叶斯超参优化。有别于的网格搜索和随机搜索独立于前几次搜索结果的搜索，贝叶斯则是利用历史的搜索结果进行优化搜索。其主要有四部分组成，1.目标函数，大部分情况下就是模型验证集上的损失。2、搜索空间，即各类待搜索的超参数。3、优化策略，建立的概率模型和选择超参数的方式。4、历史的搜索结果。首先对搜索空间进行一个先验性的假设猜想，即假设一种选择超参的方式，然后不断的优化更新概率模型，最终的目标是找到验证集上误差最小的一组超参数。

3.么是神经网络架构搜索（NAS）

2015至2017年间，是CNN网络设计最兴盛的阶段，大多都是由学者人工设计的网络结构。这个过程通常会很繁琐。其主要原因在于对不同模块组件的组成通常是个黑盒优化的问题，此外，在不同结构超参数以及训练超参数的选择优化上非凸优化问题，或者是个混合优化问题，既有离散空间又有连续空间。NAS（Neural Architecture Search）的出现就是为了解决如何通过机器策略和自动化的方式设计出优秀高效的网络。而这种策略通常不是统一的标准，不同的网络结合实际的需求通常会有不同的设计，比如移动端的模型会在效率和精度之间做平衡。目前的网络架构搜索通常会分为三个方面，搜索空间，搜索策略以及评价预估。链接 | https://www.paperweekly.site/papers/2249

a:搜索空间，定义了优化问题的变量，网络结构和超参数的变量定义有所不同，不同的变量规模对于算法的难度来说也不尽相同。早期很多工作都是用以遗传算法为代表的进化算法对神经网络的超参数和权重进行优化，因为当时的神经网络只有几层，每层十几个神经元，也不存在复杂的网络架构，参数很有限，可直接进行优化。而深度学习模型一方面有着复杂的网络结构，另一方面权重参数通常都以百万到亿来计，进化算法根本无法优化。但换个思路，假如我们找到了一组网络架构参数和对应的超参数，深度学习模型的性能其实是由这组参数来控制和决定的，所以只需要对复杂模型的架构参数和对应的超参数进行优化即可。

b:搜索策略， 搜索策略定义了使用怎样的算法可以快速、准确找到最优的网络结构参数配置。常见的搜索方法包括：随机搜索、贝叶斯优化、进化算法、强化学习、基于梯度的算法。其中，2017 年谷歌大脑的那篇强化学习搜索方法将这一研究带成了研究热点，后来 Uber、Sentient、OpenAI、Deepmind 等公司和研究机构用进化算法对这一问题进行了研究，这个 task 算是进化算法一大热点应用。

c:评价预估，类似于工程优化中的代理模型（surrogate model），因为深度学习模型的效果非常依赖于训练数据的规模，大规模数据上的模型训练会非常耗时，对优化结果的评价将会非常耗时，所以需要一些手段去做近似的评估。

一种思路是用一些低保真的训练集来训练模型，低保真在实际应用可以有多种表达，比如训练更少的次数，用原始训练数据的一部分，低分辨率的图片，每一层用更少的滤波器等。用这种低保真的训练集来测试优化算法会大大降低计算时间，但也存在一定的 bias，不过选择最优的架构并不需要绝对数值，只需要有相对值就可以进行排序选优了；

另一种主流思路是借鉴于工程优化中的代理模型，在很多工程优化问题中，每一次优化得到的结果需要经过实验或者高保真仿真（有限元分析）进行评价，实验和仿真的时间非常久，不可能无限制地进行评价尝试，学者们提出了一种叫做代理模型的回归模型，用观测到的点进行插值预测，这类方法中最重要的是在大搜索空间中如何选择尽量少的点预测出最优结果的位置；

第三种主流思路是参数级别的迁移，用之前已经训练好的模型权重参数对target问题进行赋值，从一个高起点的初值开始寻优将会大大地提高效率。在这类问题中，积累了大量的历史寻优数据，对新问题的寻优将会起到很大的帮助，用迁移学习进行求解，是一个很不错的思路；另一种比较有意思的思路叫做单次（One-Shot）架构搜索，这种方法将所有架构视作一个 one-shot 模型（超图）的子图，子图之间通过超图的边来共享权重。
